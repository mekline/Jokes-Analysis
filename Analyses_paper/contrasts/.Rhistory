allSigChange = rbind(allSigChange, myResults)
#View(allSigChange)
#New 10/12: Localizer analysis shows that VMPFC localizer doesn't come out in this dataset, so remove it from
#the joke-lit tests for ToM and ToM custom (but leave it for the localizer itself)
allSigChange = allSigChange %>%
filter(!(Group == 'ToM' & ROIName =='VMPFC')) %>%
filter(!(Group == 'ToMCustom' & ROIName =='VMPFC'))
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, ROI, Contrast, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, Contrast)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
#View(allTests)
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/reproducible analyses")
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
########
# Report those T tests like we want for the paper
########
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
###
#RESP LOCALIZER
allTests %>%
filter(Group == 'LHLang-toLang', contrastName == 'sent-non') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
#allTests %>%
#  filter(Group == 'RHLang-toLang', contrastName == 'sent-non') %>%
#  summarise(n(), sum(sig), reportTests(t,p)) #found a surprise nonsig!
allTests %>%
filter(Group == 'RHLang-toLang', contrastName == 'sent-non', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang-toLang', contrastName == 'sent-non', !sig)
###MD localizer check
allTests %>%
#filter(Group == 'MDRight-toLang', contrastName == 'non-sent') %>%
#summarise(n(), sum(sig), reportTests(t,p))
filter(Group == 'MDRight-toLang', contrastName == 'non-sent', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight-toLang', contrastName == 'non-sent', !sig)
allTests %>%
filter(Group == 'ToM-toToM', contrastName == 'bel-pho', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM-toToM', contrastName == 'bel-pho', !sig)
#This rebuilds the t tests that spmss spits out from the individual signal change values (reproduced here from ind.
#signal change values so mk can track how those are done/feed into other analyses)
rm(list=ls(all=TRUE))
library(tidyr)
library(dplyr)
library(pwr)
#Set wd!
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/contrasts")
#######
# Read in all contrast values
#######
# Add in the contrast and ROI names so it's not just numbers!!!!!
RHLangROI.Names = c('RPostTemp', 'RAntTemp', 'RAngG', 'RIFG',      'RMFG',     'RIFGorb');
LangROI.Names = c('LPostTemp', 'LAntTemp', 'LAngG', 'LIFG',      'LMFG',     'LIFGorb');
MDROI.Names = c('LIFGop',  'RIFGop', 'LMFG',    'RMFG',    'LMFGorb',
'RMFGorb', 'LPrecG', 'RPrecG',  'LInsula', 'RInsula',
'LSMA',    'RSMA',   'LParInf', 'RParInf', 'LParSup',
'RParSup', 'LACC',   'RACC');
ToMROI.Names = c('DMPFC', 'LTPJ',  'MMPFC', 'PC',
'RTPJ',  'VMPFC', 'RSTS');
lang.contrasts = c('sent','non','sent-non')
revlang.contrasts = c('sent','non','non-sent')
md.contrasts = c()
tom.contrasts = c('bel','pho','bel-pho')
normal.contrasts = c('joke', 'lit', 'joke-lit')
custom.contrasts = c('low','med','high','other','paramfun')
###RESP LOCALIZER
myResults = read.csv('RHLangfROIsrespLangLoc.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = lang.contrasts[Contrast])%>%
mutate(Group = 'RHLang-toLang')
allSigChange = myResults
myResults = read.csv('LangfROIsrespLangLoc.csv')%>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = lang.contrasts[Contrast])%>%
mutate(Group = 'LHLang-toLang')
allSigChange = rbind(allSigChange, myResults)
##TO ADD: MD to Lang localizer measure (Non should > Sent)
myResults = read.csv('MDfROIsrespRevLangLoc.csv')%>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = revlang.contrasts[Contrast])%>%
mutate(Group = 'MDall-toLang')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft-toLang'
allSigChange[(allSigChange$Group == 'MDall-toLang') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight-toLang'
View(allSigChange)
myResults = read.csv('NewToMfROIsrespToMLoc.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = tom.contrasts[Contrast])%>%
mutate(Group = 'ToM-toToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES
myResults = read.csv('RHLangfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'RHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('LangfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'LHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('MDfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'MDAll')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft'
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight'
myResults = read.csv('NewToMfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'ToM')
allSigChange = rbind(allSigChange, myResults)
###RESP JOKES-CUSTOM with paramfun #10/07 new thing for supp. materials
myResults = read.csv('NewToMfROIsrespNonlitJokesCustom_20161007.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = custom.contrasts[Contrast])%>%
mutate(Group = 'ToMCustom')
allSigChange = rbind(allSigChange, myResults)
#View(allSigChange)
#New 10/12: Localizer analysis shows that VMPFC localizer doesn't come out in this dataset, so remove it from
#the joke-lit tests for ToM and ToM custom (but leave it for the localizer itself)
allSigChange = allSigChange %>%
filter(!(Group == 'ToM' & ROIName =='VMPFC')) %>%
filter(!(Group == 'ToMCustom' & ROIName =='VMPFC'))
#######
# Calculate T Tests
#######
allTests <- allSigChange %>%
group_by(Group)%>%
summarize(familySize = length(unique(ROI))) %>%
merge(allSigChange) %>%
group_by(Group, ROI, Contrast, ROIName, contrastName, familySize) %>%
summarise(t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value) %>%
ungroup()%>%
group_by(Group, Contrast)%>%
mutate(p.adj = p.adjust(p, method="fdr", n=familySize[1]))%>%
ungroup()
#View(allTests)
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/reproducible analyses")
zz = file('localizer_t_tests_all.csv', 'w')
write.csv(allTests, zz, row.names=FALSE)
close(zz)
########
# Report those T tests like we want for the paper
########
#Do corrections ever matter?
allTests <- allTests %>%
mutate(sig = p < 0.05) %>%
mutate(sigCor = p.adj < 0.05) %>%
mutate(mismatch = sig != sigCor)
View(filter(allTests,mismatch))
#Convention: when all tests go one way, report them together as follows:
reportTests <- function(ts, ps){
if (all(ps > 0.05)){
paste('all insig, ts <', max(ts), 'ps>', min(ps))
} else if (all(ps < 0.05)){
paste('all sig, ts >', min(ts), 'ps<', max(ps))
} else {
'explore...'
}
}
###
#RESP LOCALIZER
allTests %>%
filter(Group == 'LHLang-toLang', contrastName == 'sent-non') %>%
summarise(n(), sum(sig), reportTests(t,p)) #Convention: when all significant, report the largest p
#allTests %>%
#  filter(Group == 'RHLang-toLang', contrastName == 'sent-non') %>%
#  summarise(n(), sum(sig), reportTests(t,p)) #found a surprise nonsig!
allTests %>%
filter(Group == 'RHLang-toLang', contrastName == 'sent-non', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang-toLang', contrastName == 'sent-non', !sig)
###MD localizer check
allTests %>%
#filter(Group == 'MDRight-toLang', contrastName == 'non-sent') %>%
#summarise(n(), sum(sig), reportTests(t,p))
filter(Group == 'MDRight-toLang', contrastName == 'non-sent', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight-toLang', contrastName == 'non-sent', !sig)
allTests %>%
filter(Group == 'MDLeft-toLang', contrastName == 'non-sent', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDLeft-toLang', contrastName == 'non-sent', !sig)
allTests %>%
filter(Group == 'ToM-toToM', contrastName == 'bel-pho', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM-toToM', contrastName == 'bel-pho', !sig)
###
#RESP JOKES
### RHLang
#Jokes and Nonjokes both activate, but no differences.
allTests %>%
filter(Group == 'RHLang', contrastName == 'joke', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang', contrastName == 'joke', !sig)
allTests %>%
filter(Group == 'RHLang', contrastName == 'lit', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'RHLang', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'RHLang', contrastName == 'joke-lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
### LHLang
#Jokes and Nonjokes both activate, but no differences.
allTests %>%
filter(Group == 'LHLang', contrastName == 'joke') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', contrastName == 'lit') %>%
summarise(n(), sum(sig), reportTests(t,p))
allTests %>%
filter(Group == 'LHLang', contrastName == 'joke-lit', !sig) %>%
summarise(n(), sum(sig), reportTests(t,p)) #ONLY ONE of the ROIs significant
filter(allTests, Group == 'LHLang', contrastName == 'joke-lit', sig)
### RHMD
# RH is pretty boring
allTests %>%
filter(Group == 'MDRight', contrastName == 'joke', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'joke', !sig)
allTests %>%
filter(Group == 'MDRight', contrastName == 'lit',sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'MDRight', contrastName == 'joke-lit', !sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDRight', contrastName == 'joke-lit', sig)
###LHMD
# LH has some joke-lit differences
allTests %>%
filter(Group == 'MDLeft', contrastName == 'joke', sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDLeft', contrastName == 'joke', !sig)
allTests %>%
filter(Group == 'MDLeft', contrastName == 'lit',sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDLeft', contrastName == 'lit', !sig)
allTests %>%
filter(Group == 'MDLeft', contrastName == 'joke-lit', !sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'MDLeft', contrastName == 'joke-lit', sig)
### ToM
# Interesting activations!
allTests %>%
filter(Group == 'ToM', contrastName == 'joke',!sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'joke', sig)
allTests %>%
filter(Group == 'ToM', contrastName == 'lit', !sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'lit', sig)
allTests %>%
filter(Group == 'ToM', contrastName == 'joke-lit', !sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'joke-lit', sig)
#10/14 Huh, where did the ToM paramfun test go? Here it is again...
allTests %>%
filter(Group == 'ToMCustom', contrastName == 'paramfun',!sig) %>%
summarise(n(), sum(sig), reportTests(t,p))
filter(allTests, Group == 'ToM', contrastName == 'joke-lit', sig)
#Let's try and do a power analysis on the Jokes results. (Considering a replication
#since a journal has asked for one) There are 4 regions we expect to
#find differences in: RTPJ, LTPJ, MMPFC, PC.  How big are those differences and how
#well powered are we?
cohens_d <- function(x, y) {
lx <- length(x)- 1
ly <- length(y)- 1
md  <- abs(mean(x) - mean(y))        ## mean difference (numerator)
csd <- lx * var(x) + ly * var(y)
csd <- csd/(lx + ly)
csd <- sqrt(csd)                     ## common sd computation
cd  <- md/csd                        ## cohen's d
}
forPower <- allSigChange %>%
filter(Group == 'ToM', contrastName == 'joke-lit') %>%
filter(ROIName %in% c('RTPJ','LTPJ','PC','MMPFC') ) %>%
group_by(ROIName)%>%
summarise(m = mean(sigChange), sd = sd(sigChange), t = t.test(sigChange, mu=0,alt='greater')$statistic,
p = t.test(sigChange, mu=0,alt='greater')$p.value)
forPower$n <- 12
forPower$cohens_d <- forPower$m / forPower$sd
ptests <- mapply(pwr.t.test, n=forPower$n, d=forPower$cohens_d, sig.level=0.05, alternative='greater')
#
ptests
#Assume the smallest effect in ToM regions is the true effect size
effect_est <- max(forPower$cohens_d)
effect_est
#Assume the smallest effect in ToM regions is the true effect size
effect_est <- min(forPower$cohens_d)
effect_est
#How many participants do we need for 80% power at p=0.05?
pwr.t.test(d=effect_est, sig.level=0.05, power = 0.8, alternative='greater')
#How many participants do we need for 80% power at p=0.05?
pwr.t.test(d=effect_est, sig.level=0.05, power = 0.95, alternative='greater')
View(myResults)
View(allSigChange)
View(allSigChange)
unique(allSigChange$Group)
#This file reads in ALL the %-signal-change values, per-participant, per-parcel, per-contrast,
# Those %-signal-change calculations are produced by the awesome toolbox analyses, and represent a single overall calculation
#derived for the whole parcel region (not individual voxels, as mk sometimes forgets)
rm(list = ls())
library(bootstrap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/contrasts/")
########
#READ IN DATA
########
#Here, we read in all those files, calculate a whole passle of mean and standard error bars, and then make graphs
# Add in the contrast and ROI names so it's not just numbers!!!!! (This ordering comes from the
# standard ordering produced by the 2nd level analyses; we'll arrange differently in the plots)
RHLangROI.Names = c('RPost Temp', 'RAnt Temp', 'RAngG', 'RIFG',      'RMFG',     'RIFG orb');
LangROI.Names = c('LPost Temp', 'LAnt Temp', 'LAngG', 'LIFG',      'LMFG',     'LIFG orb');
MDROI.Names = c('LIFG op',  'RIFG op', 'LMFG',    'RMFG',    'LMFG orb',
'RMFG orb', 'LPrecG', 'RPrecG',  'LInsula', 'RInsula',
'LSMA',    'RSMA',   'LPar Inf', 'RPar Inf', 'LPar Sup',
'RPar Sup', 'LACC',   'RACC');
ToMROI.Names = c('DM PFC', 'LTPJ',  'MM PFC', 'PC',
'RTPJ',  'VM PFC', 'RSTS');
normal.contrasts = c('joke', 'lit', 'joke-lit')
custom.contrasts = c('low','med','high','other')
myResults = read.csv('RHLangfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'RHLang')
allSigChange = myResults
myResults = read.csv('LangfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'LHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('MDfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'MDAll')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft'
allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight'
#Little extra for ToM: Remove the VMPFC because it did not replicate the basic localizer finding.
myResults = read.csv('NewToMfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'ToM') %>%
filter(ROIName !="VM PFC")
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('NewToMfROIsresCustomJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = custom.contrasts[Contrast])%>%
mutate(Group = 'ToMCustom')%>%
filter(ROIName !="VM PFC")
allSigChange = rbind(allSigChange, myResults)
#########
# TRANSFORMATIONS
#########
#First, in addition to the by-region signal changes, we are going to give each person an average signal change value for each localizer
avgSigChange = aggregate(allSigChange$sigChange, by=list(allSigChange$Group,allSigChange$SubjectNumber,allSigChange$contrastName), mean)
names(avgSigChange) = c('Group','SubjectNumber', 'contrastName','sigChange')
avgSigChange$ROIName = 'LocalizerAverage'
avgSigChange$ROI = 0
allSigChange <- allSigChange %>%
dplyr::select(one_of(c('Group','ROIName', 'ROI','SubjectNumber', 'contrastName','sigChange')))
allSigChange <- rbind(allSigChange, avgSigChange)
#Drop the contrasts we're not interested in...
toGraph = allSigChange %>%
filter(contrastName %in% c('joke','lit','high','med','low'))
#Next, get the table that we'll be making the graphs from: for each region (including the average region), take all
#the individual signal changes and calculate a mean and a standard error
sterr <- function(mylist){
my_se = sd(mylist)/sqrt(length(mylist))
return(my_se)
}
mystats = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$ROIName, toGraph$ROI,toGraph$contrastName), mean)
names(mystats) = c('Group','ROIName', 'ROI','contrastName', 'themean')
myster = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$ROIName, toGraph$ROI,toGraph$contrastName), sterr)
names(myster) = c('Group','ROIName', 'ROI','contrastName', 'sterr')
mystats = merge(mystats,myster)
mystats$se_up = mystats$themean + mystats$sterr
mystats$se_down = mystats$themean - mystats$sterr
View(mystats)
help(write.csv)
avgz <- filter(mystats, ROIName == 'LocalizerAverage')
avgz
write.csv(avgz, 'jokes_localizer_avg.csv')
pwd
get.dir()
getwd()
#This file reads in ALL the %-signal-change values, per-participant, per-parcel, per-contrast,
# Those %-signal-change calculations are produced by the awesome toolbox analyses, and represent a single overall calculation
#derived for the whole parcel region (not individual voxels, as mk sometimes forgets)
rm(list = ls())
library(bootstrap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
setwd("~/Dropbox/_Projects/Jokes - fMRI/Jokes-Analysis Repository/Analyses_paper/contrasts/")
########
#READ IN DATA
########
#Here, we read in all those files, calculate a whole passle of mean and standard error bars, and then make graphs
# Add in the contrast and ROI names so it's not just numbers!!!!! (This ordering comes from the
# standard ordering produced by the 2nd level analyses; we'll arrange differently in the plots)
RHLangROI.Names = c('RPost Temp', 'RAnt Temp', 'RAngG', 'RIFG',      'RMFG',     'RIFG orb');
LangROI.Names = c('LPost Temp', 'LAnt Temp', 'LAngG', 'LIFG',      'LMFG',     'LIFG orb');
MDROI.Names = c('LIFG op',  'RIFG op', 'LMFG',    'RMFG',    'LMFG orb',
'RMFG orb', 'LPrecG', 'RPrecG',  'LInsula', 'RInsula',
'LSMA',    'RSMA',   'LPar Inf', 'RPar Inf', 'LPar Sup',
'RPar Sup', 'LACC',   'RACC');
ToMROI.Names = c('DM PFC', 'LTPJ',  'MM PFC', 'PC',
'RTPJ',  'VM PFC', 'RSTS');
normal.contrasts = c('joke', 'lit', 'joke-lit')
custom.contrasts = c('low','med','high','other')
myResults = read.csv('RHLangfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = RHLangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'RHLang')
allSigChange = myResults
myResults = read.csv('LangfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = LangROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast])%>%
mutate(Group = 'LHLang')
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('MDfROIsrespNonlitJokes.csv') %>%
mutate(ROIName = MDROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'MDAll')
allSigChange = rbind(allSigChange, myResults)
#Little extra thing here, rename MD to split by L and R hemisphere!
#allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 1),]$Group = 'MDLeft'
#allSigChange[(allSigChange$Group == 'MDAll') & (allSigChange$ROI %%2 == 0),]$Group = 'MDRight'
#Little extra for ToM: Remove the VMPFC because it did not replicate the basic localizer finding.
myResults = read.csv('NewToMfROIsrespNonlitJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = normal.contrasts[Contrast]) %>%
mutate(Group = 'ToM') %>%
filter(ROIName !="VM PFC")
allSigChange = rbind(allSigChange, myResults)
myResults = read.csv('NewToMfROIsresCustomJokes.csv')%>%
mutate(ROIName = ToMROI.Names[ROI]) %>%
mutate(contrastName = custom.contrasts[Contrast])%>%
mutate(Group = 'ToMCustom')%>%
filter(ROIName !="VM PFC")
allSigChange = rbind(allSigChange, myResults)
#########
# TRANSFORMATIONS
#########
#First, in addition to the by-region signal changes, we are going to give each person an average signal change value for each localizer
avgSigChange = aggregate(allSigChange$sigChange, by=list(allSigChange$Group,allSigChange$SubjectNumber,allSigChange$contrastName), mean)
names(avgSigChange) = c('Group','SubjectNumber', 'contrastName','sigChange')
avgSigChange$ROIName = 'LocalizerAverage'
avgSigChange$ROI = 0
allSigChange <- allSigChange %>%
dplyr::select(one_of(c('Group','ROIName', 'ROI','SubjectNumber', 'contrastName','sigChange')))
allSigChange <- rbind(allSigChange, avgSigChange)
#Drop the contrasts we're not interested in...
toGraph = allSigChange %>%
filter(contrastName %in% c('joke','lit','high','med','low'))
#Next, get the table that we'll be making the graphs from: for each region (including the average region), take all
#the individual signal changes and calculate a mean and a standard error
sterr <- function(mylist){
my_se = sd(mylist)/sqrt(length(mylist))
return(my_se)
}
mystats = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$ROIName, toGraph$ROI,toGraph$contrastName), mean)
names(mystats) = c('Group','ROIName', 'ROI','contrastName', 'themean')
myster = aggregate(toGraph$sigChange, by=list(toGraph$Group, toGraph$ROIName, toGraph$ROI,toGraph$contrastName), sterr)
names(myster) = c('Group','ROIName', 'ROI','contrastName', 'sterr')
mystats = merge(mystats,myster)
mystats$se_up = mystats$themean + mystats$sterr
mystats$se_down = mystats$themean - mystats$sterr
#Print out a simple summary for mega-graphs
avgz <- filter(mystats, ROIName == 'LocalizerAverage')
write.csv(avgz, 'jokes_localizer_avg.csv')
